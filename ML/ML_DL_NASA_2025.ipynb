{"cells":[{"cell_type":"markdown","metadata":{"id":"RgMyA5dmwFJO"},"source":["# <font color=#023F7C> **Machine Learning and Deep Learning**\n","\n","---\n","\n","\n","\n","<font color=#023F7C>**Hi! PARIS DataBootcamp 2024 üöÄ**</font> <br>\n","\n","\n","<img src = https://www.hi-paris.fr/wp-content/uploads/2020/09/logo-hi-paris-retina.png width = \"300\" height = \"200\" >\n","\n","\n","**Name**: ...           <br>\n","**School**: ...         <br>\n","**Group number**: ...    <br>\n","**Track**: ...           <br>\n","**Teaching Assistants**: Thibault Porssut and Farouk Kadri, Machine Learning Research Engineer @ Hi! PARIS"]},{"cell_type":"markdown","metadata":{"id":"epycO8NUwFJQ"},"source":["# **1. Important guidelines**\n","\n","\n","The RUL (Remaining Useful Life) refers to the remaining lifespan of an aircraft engine before failure. In the context of the NASA C-MAPSS dataset, this term represents the number of operational cycles an engine can still perform before breaking down. **The goal of this practical session** is to build a Machine Learning model that can p**redict this value using sensor data collected during previous cycles.**\n","\n","To achieve this goal, you are provided with three datasets: train_FD001.txt, test_FD001.txt, and RUL_FD001.txt, originating from the NASA C-MAPSS dataset. <br>\n","These datasets contain sensor measurements and operational settings for multiple aircraft engines recorded over a series of operational cycles. Each engine is run until it fails, and the sensor data capture the degradation process over time. <br>\n","The file RUL_FD001.txt contains the actual Remaining Useful Life (RUL) values for the engines in the test set at the point where the test data end.\n","\n","The variable to predict is RUL, which represents the number of operational cycles remaining before the engine fails."]},{"cell_type":"markdown","metadata":{"id":"yISGPg8WwFJQ"},"source":["**<font size='5'><u>How to work on this notebook</u>**</font> <br>\n","The notebook is split in two parts: Machine Learning and Deep Learning.\n","\n","- **Beginner track**: You only have to complete the Machine Learning and Deeep Learning section.\n","- **Intermediate track**: Please complete Machine Learning, Deep Learning and the optional section."]},{"cell_type":"markdown","metadata":{"id":"SGP2HYohwFJR"},"source":["**<font size='5'><u>Bootcamp deliverables</u>**</font> <br>\n","\n","Here are the two deadlines for the bootcamp deliverables:\n","- <u>**Friday 12:30 PM**</u>: <br> Send us the \"Machine Learning and Deep Learning\" notebooks (no need to send us data cleaning) <br>\n","    - **Each group member should send his own notebooks** (we won't accept one notebook per group)\n","    - Don't forget to complete the start of the notebook with your information (name, school, group number and track)\n","    \n","- <u>**Friday 2:30PM**</u>: <br>Send us the group slides <br>\n","    - You can send us a single powerpoint per group (no need to send us one per group member)\n","    - Don't forget to add your group number as well as who is in your group (name, school and track) to the slides\n","\n","Send both the notebooks and the slides at `data-event@hi-paris.fr`"]},{"cell_type":"markdown","metadata":{"id":"1qfwFdDPwFJR"},"source":["**<font size='5'><u>Need help ? üôè</u>**</font> <br>\n","\n","We will drop later in the week to the Machine Learning course (Beginner track) on HFactory the `Machine_Learning_Beginner_DB2025.ipynb` notebook for those who need help with the Machine Learning part.\n","\n","**Don't hesitate to ask questions to the bootcamp organizers/staff members if you need help.**\n"]},{"cell_type":"markdown","metadata":{"id":"xCheKJQBwFJR"},"source":["# **2. Machine Learning**\n","\n","Let's start by importing the libraries needed for this notebook."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZyhKqCkh5D8S","tags":[],"executionInfo":{"status":"ok","timestamp":1755532025575,"user_tz":-120,"elapsed":1374,"user":{"displayName":"Thibault Porssut","userId":"11631798829447041123"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import time"]},{"cell_type":"markdown","metadata":{"id":"XcOZ9GW8wFJS"},"source":["Now load the train and test datasets using `pd.read_csv()`"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"dVLd2Z_jwFJT","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755532027894,"user_tz":-120,"elapsed":829,"user":{"displayName":"Thibault Porssut","userId":"11631798829447041123"}},"outputId":"c54ff7bc-5d9d-4f33-bb17-b30f5a3f7652"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (18816, 28)\n","Test shape: (12039, 28)\n"]}],"source":["train_path =  '02_df_train_FD001_wo_nan_denoised.csv'\n","test_path = '02_df_test_FD001_wo_nan_denoised.csv'\n","\n","# Train and test data.\n","train_df = pd.read_csv(train_path)\n","test_df = pd.read_csv(test_path)\n","\n","print(\"Train shape:\", train_df.shape)\n","print(\"Test shape:\", test_df.shape)"]},{"cell_type":"markdown","metadata":{"id":"Hr9tR1BnwFJV"},"source":["### **2.1 Data preprocessing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jfuHVWn9wFJV"},"outputs":[],"source":["# Preprocessing tools\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eO2HwJWVoRsb"},"outputs":[],"source":["def replace_with_gaussian_bins(df, cols):\n","    \"\"\"\n","    Replace numerical columns with 7-category Gaussian bins based on mean ¬± n*std.\n","\n","    Parameters:\n","    df   : DataFrame\n","    cols : list of column names to transform\n","\n","    Returns:\n","    DataFrame with the same structure but selected numeric columns replaced with categorical bins\n","    \"\"\"\n","    df_out = df.copy()\n","\n","    labels = [\n","        \"Extremely Low\",\n","        \"Very Low\",\n","        \"Low\",\n","        \"Normal\",\n","        \"High\",\n","        \"Very High\",\n","        \"Extremely High\"\n","    ]\n","\n","    for col in cols:\n","        mu = df_out[col].mean()\n","        sigma = df_out[col].std()\n","\n","        bins = [\n","          -np.inf,\n","          mu - 2*sigma,   # Extremely Low\n","          mu - 1*sigma,   # Very Low\n","          mu - 0.5*sigma,   # Low\n","          mu + 0.5*sigma,   # High\n","          mu + 1*sigma,   # Very High\n","          mu + 2*sigma,   # Extremely High\n","          np.inf\n","      ]\n","\n","        df_out[col] = pd.cut(df_out[col], bins=bins, labels=labels, include_lowest=True)\n","\n","    return df_out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWH8j9OpDeYa"},"outputs":[],"source":["train_df=replace_with_gaussian_bins(train_df,[\"HPC outlet temperature (¬∞C)\"])\n","test_df=replace_with_gaussian_bins(test_df,[\"HPC outlet temperature (¬∞C)\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z1yz5wfVwXi0"},"outputs":[],"source":["\n","\n","features = ['engine_unit_number',\n","  'time_cycles',\n","  'LPC outlet temperature (¬∞C)',\n","  \"HPC outlet temperature (¬∞C)\",\n","  \"LPT outlet temperature (¬∞C)\",\n","  \"HPC outlet pressure (bar)\",\n","  \"Physical core speed (rpm)\",\n","  \"Fuel flow / Ps30 (kg/s/bar)\",\n","  \"Corrected fan speed (rpm)\",\n","  \"Bypass ratio (dimensionless)\",\n","  \"Bleed enthalpy (kJ/kg)\",\n","  \"HPT coolant bleed flow (kg/s)\"]\n","\n","\n","\n","X_train = train_df[features].copy()\n","y_train = train_df[\"RUL_class\"].copy()\n","\n","X_test = test_df[features].copy()\n","y_test = test_df[\"RUL_class\"].copy()\n","\n","\n","print(\"Train rows:\", X_train.shape[0], \"Test engines:\", X_test.shape[0])"]},{"cell_type":"markdown","metadata":{"id":"-4oesPDawFJW"},"source":["**<u>Question 2.1.1:</u>** <br>**Transform the categorical variables in each split with `OneHotEncoder`.** <br>\n","\n","\n","The column names OneHotEncoder creates can be accessed with `.get_feature_names_out()`. <br>\n","Go this [page](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) for more info on how to use scikit-learn's `OneHotEncoder` function. <br>\n","\n","*Don't forget, data preprocessing is only applied to the feature variables in the case of binary classification !*\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2YWJ9DzIA3VH"},"outputs":[],"source":["\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AGCZAcSPW3Di"},"source":["However label encoding is preferred over one-hot encoding for ordinal labels because ordinal features have a meaningful, intrinsic order (e.g., Low < Medium < High). Label encoding preserves this natural ranking by mapping categories to integers that reflect their order, allowing models to interpret the progression between categories. In contrast, one-hot encoding would treat each category as unrelated, discarding the ordinal relationship and increasing the number of features unnecessarily, which can reduce efficiency without adding value."]},{"cell_type":"markdown","metadata":{"id":"1glnMTcVOoZx"},"source":["**<u>Question 2.1.2:</u>** <br>**Transform the categorical variables with `LabelEncoder`.** <br>\n","\n","\n","The column names LabelEncoder creates can be accessed with `.get_feature_names_out()`. <br>\n","Go this [page](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) for more info on how to use scikit-learn's `LabelEncoder` function. <br>\n","\n","*Don't forget, data preprocessing is only applied to the feature variables in the case of binary classification !*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W51mOKEw3Ery"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"UwttVkxewFJW"},"source":["**<u>Question 2.1.3</u>**: <br>\n","**Scale the continuous variables using either `StandardScaler` (standardization) or `MinMaxScaler` (normalization).**<br>\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Dpy9DLf3Ery"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"K9P9cvpH73he"},"source":["### **2.2 Model training and evaluation**\n","Now that our dataset has been preprocessed, we can use it to train Machine Learning models.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lrOnwmzxLGdL"},"outputs":[],"source":["# Metrics for evaluation\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    confusion_matrix, roc_curve, auc, precision_recall_curve,\n","    classification_report, roc_auc_score, PrecisionRecallDisplay, average_precision_score\n",")\n","\n","# hyperparameter tuning\n","from sklearn.model_selection import GridSearchCV\n","\n","# Classification algorithms\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","# Plotting & Style\n","import seaborn as sns\n","sns.set(style=\"whitegrid\")\n"]},{"cell_type":"markdown","metadata":{"id":"XNL0EcTFwFJX"},"source":["**Train three models of your choice** (Logistic Regression, K nearest neighbor, Decision Tree,...) **using scikit-learn's `.fit()` method. <br>**\n","\n","<u>Help</u>: Train these models on the training set (`X_train` and `y_train`).\n","\n","advice: Try Random Forest\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NOqEmiJV7x-Z"},"source":["**Why classification instead of regression?**\n","\n","Although the Remaining Useful Life (RUL) is a continuous variable, here we approach the problem as classification because:\n","\n","- Classification simplifies decision-making by focusing on whether an engine is likely to fail soon (within 30 cycles) rather than predicting the exact remaining cycles.\n","- Regression models on RUL often struggle to be robust due to noise and variability in the sensor data.\n","- Classification allows for more stable, actionable predictions aligned with maintenance needs: \"replace soon\" vs \"safe\"."]},{"cell_type":"markdown","metadata":{"id":"QkHDWOJsjviz"},"source":["<u>**Question 2.2.1**:</u> <br>  Choose any three models to try. Which ones do you pick ?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nux2T3aX3Ery"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"J6LvCTBQj3uV"},"source":["<u>**Question 2.2.2**:</u> <br> Train the FIRST selected model using .fit(X_train_scaled, y_train)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_RDVxx53Ery"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"GuAK_ClYkWfE"},"source":["<u>**Question 2.2.3**:</u> <br> Train the SECOND and THIRD selected models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EP4racwN3Erz"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"NKYHRbb0ZXWE"},"source":["<u>**Question 2.2.4**:</u> <br> FIRST model: predict on TRAIN/TEST, then print Test Accuracy, Test Recall, Test F1.\n","If our goal is to catch failures, which metric should we prioritize?\n","\n","*Help: The .predict() function should be used on the feature of the test set (X_test)*. [page](https://scikit-learn.org/stable/getting_started.html)\n","\n","accuracy_score(), recall_score(), f1_score()\n","find all metrics here: [page](https://scikit-learn.org/stable/api/sklearn.metrics.html)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JuA_hW813Erz"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XfJNZewTZR93"},"source":["<u>**Question 2.2.5**:</u> <br> Repeat for the SECOND model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B3VOM8lK3Erz"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"MNr4ou0dZMMd"},"source":["<u>**Question 2.2.6**:</u> <br> Repeat for the THIRD model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5QhDE6a3Erz"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"san3ALWru88p"},"source":["You may notice that we emphasize Recall. Recall answers: ‚Äúof all the true failures, how many did the model catch?‚Äù On imbalanced datasets, a model can show high accuracy while still missing many failures (predicting the majority class most of the time). That means lots of false negatives. When the goal is failure detection, Recall is the right metric because it prioritizes catching positives (fewer missed failures), even if that sometimes increases false alarms. Keep in mind there‚Äôs a trade-off: higher Recall can lower Precision, so we pick the threshold (or settings) that gives the best compromise for our use case.\n","\n","- If Accuracy is high but Recall is low, we are missing failures (false negatives).\n","- Since the goal is to detect failures, prioritize Recall."]},{"cell_type":"markdown","metadata":{"id":"dK3BK80sYlw3"},"source":["<u>**Question 2.2.7**:</u> <br> Find the best model by TEST Recall among the three and show its TEST confusion matrix.\n","\n","*help: Look at recall_score() and confusion_matrix() [page](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DOfM9cp13Er5"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"3HOmM2SuYbzW"},"source":["<u>**Question 2.2.8**:</u> <br> Plot ROC and Precision‚ÄìRecall curves for the BEST model (needs probabilities).\n","*help: Look at roc_curve() [page](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) and precision_recall_curve() [page](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html)*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zEgdJmHm3Er5"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"tPVN_ZV6YJv8"},"source":["<u>**Question 2.2.9**:</u> <br> Pick the threshold with the highest Recall. ONLY on the best model (picked above)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LBp14o4Y3Er5"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"8pkz20L9m-Yp"},"source":["<u>**Question 2.2.10**:</u> <br> Tiny GridSearch to favor Recall.\n","\n","*Help: Try GridSearchCV [page](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) on the best model you selected (by Recall) to find hyperparameters that improve Recall.<br>\n","Report the best hyperparameters (.best_params_) and the best cross-validated Recall (.best_score_). Then re-fit the tuned model and print the Test Recall.*\n","\n","Notes (keep it simple):\n","Use scoring='recall' in GridSearchCV (we care most about catching failures).\n","Keep the grid tiny (2‚Äì3 values per parameter) to avoid long runs; set cv=3.\n","Compare against your baseline Test Recall (before tuning). One line is enough.\n","\n","*(Optional) If you tried different decision thresholds earlier (e.g., 0.4 / 0.5 / 0.6), also report Test Recall using your chosen threshold with the tuned model.*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TAMrPqRy3Er5"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Wbq6nxzYwFJa"},"source":["## **3. Explainability with shap**\n","\n","The `shap` library (SHapley Additive exPlanations) is a Python library used for explaining the output of machine learning models. <br> It provides a unified framework for interpreting complex models and understanding the contributions of individual features to model predictions. <br>\n","\n","Shap is particularly useful for understanding black-box models like boosting, random forests, and deep neural networks, among others. <br>\n","It can also be used with any classification model."]},{"cell_type":"markdown","metadata":{"id":"m8XJ_7cpwFJa"},"source":["**Let's install and import the shap library.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SRYM5HygwFJa","scrolled":true},"outputs":[],"source":["!pip install shap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_oe1lXgYwFJa"},"outputs":[],"source":["import shap\n","np.bool=bool # code from last year"]},{"cell_type":"markdown","metadata":{"id":"XZ1pnBXJwFJb"},"source":["Shap is very heavy and takes a long time to compute. <br>\n","To facilitate execution and reduce computing time, you can work on the **first 100 rows only**.\n","\n","*Note: You can use either the train features (X_train) or the test features (X_test) to compute shap values*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_TTiLTa4wyRT","tags":[]},"outputs":[],"source":["df_shap = X_train_scaled.iloc[:100]"]},{"cell_type":"markdown","metadata":{"id":"dDpCt-2owFJb"},"source":["<u>**Question 3.1**:</u> <br>\n","**Create an object `explainer` that can compute shap values.** <br>\n","\n","*<u>Help</u>: You can use `shap.Explainer` for any trained classification model as input.* <br>\n","*For tree based models, you can use `shap.TreeExplainer`*.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zEbRO7Bk3Er6"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"NXwDULXbwFJb"},"source":["**Now, compute the shap values of a model with `explainer.shap_values`.** <br>\n","If it takes too much time, you can reduce to 100-500 values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dY54i16w3Er6"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"l6LpgXg2wFJb"},"source":["<u>**Question 3.2**:</u> <br>\n","**Display the summary plot of shap values with `shap.summary_plot(...., plot_type=bar)`.**\n","\n","*Make sure you use `shap_values[0]` in your plot and not every shap value computed*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvTGZlmrw2PC"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"cBzCZ8mEwFJb"},"source":["<u>**Question 3.4**:</u> <br>\n","**Use the same shap plot as previously but replace `plot_type=\"bar\"` with `plot_type=\"dot\"`.** <br>\n","**And add the data you used to compute shap_values in `features=...`.**\n","\n","**Explain what you have understood about this plot**:\n","- **Which variables are important in terms of explainability ?**\n","- **How does the values of the important variables affect predictions ?**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYaRCaixw31F"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"T4QnxuN5wFJb"},"source":["## **4. Deep Learning**\n","\n","We will start by importing one of Python's Deep Learning libraries `tensorflow`/`keras`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqUGsRQtwFJc"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout"]},{"cell_type":"markdown","metadata":{"id":"VPm3ak4LwFJc"},"source":["In the following cells, `dataset` should be the dataset you transformed with data pre-processing (Onehotencoded, LabelEncoder,...). <br>\n","You should run the following cells to prepare the data to train a Deep Learning model."]},{"cell_type":"markdown","metadata":{"id":"aY0cj9dfwFJc"},"source":["<u>**Question 4.1**:</u> <br>\n","**Make a small neural network model using `tensorflow`/`keras`, and print the accuracy**\n","\n","*Note: You can use the following elements to train the neural network* <br>\n","- *`tf.keras.Sequential`*\n","- *`layers.Dense(INTEGER, activation='relu')`*,\n","- *`tf.keras.losses.BinaryCrossentropy`*\n","- *`model.compile(optimizer='adam', ...)`*\n","- *`model.fit`*\n","- *`model.evaluate`* with epoch ~= 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VkffQREV3Er6"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}